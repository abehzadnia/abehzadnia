<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A data enthusiast blog - another wannabe &#39;statistician&#39;</title>
    <link>/</link>
    <description>Recent content on A data enthusiast blog - another wannabe &#39;statistician&#39;</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 08 Mar 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Introduction</title>
      <link>/post/statistics/bayesian/1-introduction/bayesian-introduction/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/statistics/bayesian/1-introduction/bayesian-introduction/</guid>
      
        <description>&lt;p&gt;Bayes Rule in the discrete form, which allows us to calculate the probability of an event A given event B. This is what is called a conditional probability, and we will be working with conditional probabilities a whole lot in this module and also in the remainder of this course. One example of a conditional probability is the false positive or false negative rate of a medical test.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(A|B)= \frac{P(A\bigcap B)}{P(B)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thomas Bayes, who lived between 1702 and 1761, was a mathematician who established a mathematical basis for probability inference, that is, a means of calculating from the number of times an event has not occurred the probability that it will occur in future trials. He wrote his findings on probability in essay towards solving a problem in the Doctrine of Chances published in 1763 after his death. Thomas Bayes’ contributions are immortalized by naming a fundamental proposition in probability called Bayes’ rule after him. Lets recalculate that same probability using Bayes’ rule.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;hiv-testing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;HIV testing&lt;/h2&gt;
&lt;p&gt;n example of an organization that developed a rigorous testing for HIV was the U.S. Military, which used the following procedure for testing recruits. First, all applicants were screened with an enzyme linked immune absorbent SA, which is commonly referred to as an ELISA. If the samples tested positive then two more rounds of the same ELISA were performed. If either of those test yielded a positive result, then two Western Blot assays, that were more cumbersome to conduct, but had higher accuracy were performed. Only if both of those tests were positive, did the military determine the recruit to have an HIV infection, based on papers published at the time. For the ELISA, the true positive also refer to as the sensitivity of the test was around 93%, and the true negative rate also refer to as the specificity of the test was around 99%. For the Western block, the sensitivity was around 99.9% and the specificity was around 99.1%. We also know that by the mid 1980’s, it was estimated that 1.48 / 1000 adult Americans were HIV positive.&lt;/p&gt;
&lt;p&gt;n this lesson, we will use Bayes Rule to calculate the probability that a recruit who tested positive in the first ELISA actually has HIV. Then in the next lesson, we will consider the sequential testing results.&lt;/p&gt;
&lt;p&gt;Sensitivity (true positive) = &lt;span class=&#34;math inline&#34;&gt;\(P(+ve |HIV+) = 0.93\)&lt;/span&gt; and specifity (true negative) &lt;span class=&#34;math inline&#34;&gt;\(P(-ve|HIV-) = 0.99\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prior-probability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prior probability&lt;/h2&gt;
&lt;p&gt;ior to any testing, what probability should be assigned for recruit having HIV? Given that we don’t have any additional information about this recruit, our best guess is that they are a randomly sampled individual from this population. Hence, the prior probability we assign to this recruit having HIV is simply the prevalence of the disease in the population. That is, probability of HIV is 000148. This is called the prior probability.&lt;/p&gt;
&lt;p&gt;he prior probability of the hypothesis that the recruit has HIV is 0.00148, and the prior for the competing hypothesis that the recruit does not have HIV is simply the compliment of this probability. ### What was the probability of having HIV given the first ELISA test was positive for an American patient in mid 1980’s?&lt;/p&gt;
&lt;p&gt;The questions is asking: &lt;span class=&#34;math inline&#34;&gt;\(P(HIV|+ve) =\frac{P(HIV\bigcap +ve)}{P(+ve)}\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Prior probability&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\small P(HIV+)=\frac{1.48}{1000}=0.00148\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Probability of being positive and testing positive&lt;/em&gt;:
&lt;ul&gt;
&lt;li&gt;ELISA’s sensitivity is &lt;span class=&#34;math inline&#34;&gt;\(\small P(+ve |HIV+) = 0.93\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\small P(+ve \cap HIV+): 0.93 \times 0.00148=0.00138\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Probability of testing positive&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Patient could have been HIV+ve or HIV-ve&lt;/li&gt;
&lt;li&gt;ELISA’s specificity &lt;span class=&#34;math inline&#34;&gt;\(P(-ve|HIV-)=0.99~ P(+ve|HIV-)=0.01\)&lt;/span&gt;; therefore &lt;span class=&#34;math inline&#34;&gt;\(0.99825*0.01=0.0099852\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(+ve) = 0.0013764+0.009852 = 0.0112284\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;conclusion&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(HIV|+ve) = \frac{0.0013764}{0.0112284} ~ 0.12\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;what-was-the-probability-of-having-hiv-given-the-first-and-second-elisa-tests-were-positive-for-an-american-patient-in-mid-1980s&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What was the probability of having HIV given the first and second ELISA tests were positive for an American patient in mid 1980’s?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Prior probability of having HIV for this patient should be updated with the posteriori from the previous tests.&lt;/li&gt;
&lt;li&gt;Prior probability of having HIV &lt;span class=&#34;math inline&#34;&gt;\(P(HIV+) = 0.12\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Probability of being positive and testing positive&lt;/em&gt;:&lt;/li&gt;
&lt;li&gt;ELISA’s sensitivity is &lt;span class=&#34;math inline&#34;&gt;\(P(+ve |HIV+) = 0.93\)&lt;/span&gt; ;therefore &lt;span class=&#34;math inline&#34;&gt;\(0.93*0.12=0.1116\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(+ve \bigcap HIV+) = 0.11\)&lt;/span&gt;&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Probability of testing positive&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Patient could have been HIV+ve or HIV-ve&lt;/li&gt;
&lt;li&gt;ELISA’s specificity &lt;span class=&#34;math inline&#34;&gt;\(P(-ve|HIV-)=0.99~ P(+ve|HIV-)=0.01\)&lt;/span&gt;; therefore &lt;span class=&#34;math inline&#34;&gt;\((1-0.12)*0.01=0.0092\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(P(+ve) = 0.01+0.11 = 0.12\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Probability of a patient having HIV and testing positive twice is&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\frac{0.11}{0.12} ~ 0.92\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian&lt;/h2&gt;
&lt;p&gt;One definition of probability of an event is its relative frequency in a large number of trials. For example, if you can repeat flipping a coin indefinitely and count how many heads you get and divide that number by the number of flips, the value you obtain should be 0.5. In other words the probability of event E is defined as the proportion of times the event occurs and n trials when n goes to infinity. This is the frequentist definition of probability, suppose now that you’re indifferent between winning a dollar if event E occurs or winning a dollar if you draw a blue chip from a box with 1,000 x p blue chips and 1,000 x (1-p) white chips. This means that you’re equating the probability of events E, that’s P(E), to the probability of drawing a blue chip from this box. In other words P(E) = p. This definition of probability, based on your degree of belief, is the Bayesian definition.&lt;/p&gt;
&lt;p&gt;The frequentist definition of probability allows to define a probability for the confidence interval procedure but not for specific fixed sample. And the case of a specific fixed sample, when the data do not change, we will either always capture the true parameter or never capture it. In other words, for given confidence interval the true parameter is either in it or not. This is the same as saying that the probability that a given confidence interval captures the true parameter, is either zero or one.&lt;/p&gt;
&lt;p&gt;he Bayesian definition is a bit more flexible. Since it’s a measure of belief it allows us to describe the unknown true parameter not as a fixed value but with a probability distribution. This will let us construct something like a confidence interval, except we will be able to make probabilistic statements about the parameter falling within that range.&lt;/p&gt;
&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>Structure of Clinical Research</title>
      <link>/post/clinical_research/design/components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/clinical_research/design/components/research_design_intro/</guid>
      
        <description>&lt;p&gt;Clinical research is an essential part of practice of medicine. In short it is a project carried out by to investigate a research question - which should be focused on clinical aspect of medicine (i.e. the practice of medicine).&lt;/p&gt;
&lt;p&gt;Structure of the research is heavily dependant on the subject of interest. However, almost all studies follow a logical and focused organisation. A study has to have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Research question(s)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Which needs to be &lt;em&gt;FINER&lt;/em&gt;: feasible, interesting, novel, ethical and relevant&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Background and significance&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Put the question in context and provides rationale for the study&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Design&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Observation&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Cohort studies: participants are divided into groups and are studied over a specified time frame
&lt;ul&gt;
&lt;li&gt;Time frame: prospective or retrospective&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Cross sectional study&lt;/li&gt;
&lt;li&gt;Case control study&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Experimental&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Clinical trials&lt;/li&gt;
&lt;li&gt;Randomised blinded trials&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Subjects&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The population of interest&lt;/li&gt;
&lt;li&gt;Requires inclusion and exclusion criteria to define the population of interest&lt;/li&gt;
&lt;li&gt;Sampling: How the population will be sampled and how the participants would be recruited&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variables&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Response variable(s): what will be studied - or more commonly - measured? -Also known as: outcome variable or dependent variable -Plotted on the Y-axis&lt;/li&gt;
&lt;li&gt;Explanatory variable(s): what will be controled? the treatment
&lt;ul&gt;
&lt;li&gt;Also known as: predictor variable or independent variable&lt;/li&gt;
&lt;li&gt;Plotted on the X-axis&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Confounding variable(s): variables that may influence our measured outcomes.
&lt;ul&gt;
&lt;li&gt;This should always be factored in the study design.&lt;/li&gt;
&lt;li&gt;Randomization is a common method of minimizing the influence of confounding variables.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Statistics&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The most important and crucial part of the study&lt;/li&gt;
&lt;li&gt;Enables us to analyse and infer from our data&lt;/li&gt;
&lt;li&gt;How will we go about answering our question?&lt;/li&gt;
&lt;li&gt;Involves:
&lt;ul&gt;
&lt;li&gt;Hypothesis&lt;/li&gt;
&lt;li&gt;Estimate of the required sample size (power of the study)&lt;/li&gt;
&lt;li&gt;How data will be collected&lt;/li&gt;
&lt;li&gt;Statistical method that will analyse the data&lt;/li&gt;
&lt;li&gt;What can we infer about the hypothesis from our data&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Principles of Sampling</title>
      <link>/post/clinical_research/design/components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/clinical_research/design/components/research_design_intro/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>Principles of Sampling</title>
      <link>/post/clinical_research/design/components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/clinical_research/design/components/research_design_intro/</guid>
      
        <description>&lt;!--chapter:end:CopyOfsampling.Rmd--&gt;
&lt;p&gt;A a good research question is targeted at a specific population. For example, “What is the risk of developing lung cancer among smokers?” specifies the population of interest - those who smoke.&lt;/p&gt;
&lt;p&gt;Logistically, prospects of studying the population of interest is dim. Instead, a sample is taken as a reprasentative subset of the population.&lt;/p&gt;
&lt;p&gt;Here we will look at a few sampling t&lt;/p&gt;
&lt;p&gt;Randmised sample allows for generalisation&lt;/p&gt;
&lt;!--chapter:end:sampling.Rmd--&gt;
</description>
      
    </item>
    
    <item>
      <title>Principles of Sampling</title>
      <link>/post/clinical_research/design/components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/clinical_research/design/components/research_design_intro/</guid>
      
        <description>&lt;p&gt;A a good research question is targeted at a specific population. For example, “What is the risk of developing lung cancer among smokers?” specifies the population of interest - those who smoke.&lt;/p&gt;
&lt;p&gt;Logistically, prospects of studying the population of interest is dim. Instead, a sample is taken as a reprasentative subset of the population.&lt;/p&gt;
&lt;p&gt;Here we will look at a few sampling t&lt;/p&gt;
&lt;p&gt;Randmised sample allows for generalisation&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Principles of Sampling</title>
      <link>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>Principles of Sampling</title>
      <link>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>Principles of Sampling</title>
      <link>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</guid>
      
        <description>&lt;p&gt;A a good research question is targeted at a specific population. For example, “What is the risk of developing lung cancer among smokers?” specifies the population of interest - those who smoke.&lt;/p&gt;
&lt;p&gt;Logistically, prospects of studying the population of interest is dim. Instead, a sample is taken as a reprasentative subset of the population.&lt;/p&gt;
&lt;p&gt;Here we will look at a few sampling t&lt;/p&gt;
&lt;p&gt;Randmised sample allows for generalisation&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Principles of Sampling</title>
      <link>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</link>
      <pubDate>Mon, 26 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/research_methodology/research-design/clinical-research-components/research_design_intro/</guid>
      
        <description>&lt;p&gt;A a good research question is targeted at a specific population. For example, &amp;ldquo;What is the risk of developing lung cancer among smokers?&amp;rdquo; specifies the population of interest - those who smoke.&lt;/p&gt;

&lt;p&gt;Logistically, prospects of studying the population of interest is dim. Instead, a sample is taken as a reprasentative subset of the population.&lt;/p&gt;

&lt;p&gt;Here we will look at a few sampling t&lt;/p&gt;

&lt;p&gt;Randmised sample allows for generalisation&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Bivariate Analysis</title>
      <link>/post/statistics/eda/eda_bivariate_analysis/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/statistics/eda/eda_bivariate_analysis/</guid>
      
        <description>&lt;p&gt;&lt;strong&gt;Bivariate analysis&lt;/strong&gt; explore the possible relationship between two variables&amp;rsquo; variability. In view of &amp;ldquo;&lt;strong&gt;exploratory&lt;/strong&gt;&amp;rdquo; focus of EDA, we should refrain from infering based on bivariate analysis.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;covariance&#34;&gt;Covariance&lt;/h2&gt;

&lt;p&gt;Covariance examines the joint varaince of two variables. In univariate analysis we looked at measures of: &lt;strong&gt;centre&lt;/strong&gt;, &lt;strong&gt;spread&lt;/strong&gt; and &lt;strong&gt;skewness&lt;/strong&gt;. Comparing means at the EDA stage is as simple as calculating seperate means for each variable while &lt;em&gt;refraining&lt;/em&gt; from inference!&lt;/p&gt;

&lt;p&gt;Covariance between two varaiables &lt;code&gt;\(X\)&lt;/code&gt; and &lt;code&gt;\(Y\)&lt;/code&gt; can be calculated as:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$Cov[XY] = \sigma_XY = E\ [\ (X - \overline{X})\ (Y - \overline{Y})\ ] \\ \ \\ = \frac{1}{N - 1} \sum_{i = 1}^{N}(x_i - \overline{X})(y_i - \overline{Y})$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Covariance is a generalised version of the variance formula. For example, for a single variable we&amp;rsquo;d have &lt;code&gt;\(Cov[XX] = E\ [\ (X - \overline{X})^2\ ] = Var[X]\)&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;expand&#34;&gt;
    &lt;div class=&#34;expand-label&#34; style=&#34;cursor: pointer;&#34; onclick=&#34;$h = $(this);$h.next(&#39;div&#39;).slideToggle(100,function () {$h.children(&#39;i&#39;).attr(&#39;class&#39;,function () {return $h.next(&#39;div&#39;).is(&#39;:visible&#39;) ? &#39;fa fa-chevron-down&#39; : &#39;fa fa-chevron-right&#39;;});});&#34;&gt;
        &lt;i style=&#34;font-size:x-small;&#34; class=&#34;fa fa-chevron-right&#34;&gt;&lt;/i&gt;
        &lt;span&gt;
        
        
        Example
        
        &lt;/span&gt;
    &lt;/div&gt;
    &lt;div class=&#34;expand-content&#34; style=&#34;display: none;&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kn&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;MASS&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
data&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;leuk&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;rbc &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# making up a new&lt;/span&gt;
var&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 1189517888&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;var&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;rbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 190322862&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;cov&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;rbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#lower Var in RBc has pulled down the joint variability&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 475807155&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;correlation-coefficient&#34;&gt;Correlation coefficient&lt;/h2&gt;

&lt;p&gt;Correlation coefficient measures the strength of the relationship.
&lt;code&gt;$$CC_xy = \rho_xy = \frac{\sigma_xy}{\sigma_x \sigma_y} = \frac{1}{N-1} \sum_{i = 1}^{N} \frac{(x_i - \overline{X})}{\sigma_x} \frac{(y_i - \overline{Y})}{\sigma_y}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The formula is the same for &lt;code&gt;\(r_xy\)&lt;/code&gt; - as in the sample statistics rather than the population ( &lt;code&gt;\(\rho_xy\)&lt;/code&gt; ). CC value ranges from -1 to 1, determining the relative &lt;strong&gt;strength&lt;/strong&gt; and &lt;strong&gt;direction&lt;/strong&gt; of the relationship.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;cor&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;time&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] -0.3294525&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;rank-correlation-coefficient&#34;&gt;Rank correlation coefficient&lt;/h2&gt;

&lt;p&gt;Correlation coefficient as defined above is also known as &lt;strong&gt;Pearson r&lt;/strong&gt;. Pearson CC assumes a &lt;em&gt;linear&lt;/em&gt; relationsip. If we were interested in &lt;em&gt;non-linear&lt;/em&gt; relationship between two variables, we would need to use &lt;strong&gt;Rank Correlation Coefficient (RCC)&lt;/strong&gt; commonly known as &lt;strong&gt;Spearman r&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In RCC each variable is first sorted and then transformed as such that the smallest data point is ranked = 1 and the largest Nth is ranked = n. This is known as &lt;em&gt;rank transformation&lt;/em&gt;. We would then calcualte the CC of the ranked variables rather than the raw data points.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$RCC_xy = \rho_xy(rank) = \frac{\sigma_xy(rank)}{\sigma_x(rank) \sigma_y(rank)} = \frac{1}{N-1} \sum_{i = 1}^{N} \frac{(R_{x,i} - \overline{R}_x)}{\sigma_x(rank)} \frac{(R_{y,i} - \overline{R}_y)}{\sigma_y(rank)}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The prefix &lt;em&gt;R&lt;/em&gt; denotes rank transformed values.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;cor&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;time&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; method &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;spearman&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] -0.4986164&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;notices tip&#34; &gt;&lt;p&gt;&lt;strong&gt;Spearman r&lt;/strong&gt; and &lt;strong&gt;Pearson r&lt;/strong&gt; should usually be carried out together to assess the robustness of the CC.
Spearman coefficient is more resistant to outliers (&lt;em&gt;robust measure of correlation&lt;/em&gt;). As we are not dealing with values rather the rank transformed data, outliers would not influence our correlation.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;a &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
b &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;time&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

cor&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;time&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] -0.3294525&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;cor&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;a&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# a huge reduction in our correlation strength&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] -0.114399&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;cor&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;time&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; method &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;spearman&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] -0.4986164&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;cor&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;a&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; method &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;spearman&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# only a slight difference&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] -0.4934468&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;graphical-analysis&#34;&gt;Graphical analysis&lt;/h2&gt;

&lt;p&gt;The best way to visualise the relationship between two sets of numerical variable is in fact using a scatter plot.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kn&#34;&gt;attach&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
plot&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;rbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; wbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/bivariate_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at the utility of rank transformation:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kn&#34;&gt;attach&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;Theoph&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
plot&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;Time&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; conc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# doesn&amp;#39;t look good, look at the cluster of outliers&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/bivariate_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;plot&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kp&#34;&gt;rank&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;Time&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;kp&#34;&gt;rank&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;conc&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# much better looking, we can see the Theophylline concentration increases and then decreases (due to its half life)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/bivariate_files/figure-html/unnamed-chunk-6-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;multivariate-analysis&#34;&gt;Multivariate analysis&lt;/h2&gt;

&lt;p&gt;Multivariate analysis involves calculating the CC for each pair of variables we have at hand. The result would be a matrix of correlation coefficients.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;cor&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kp&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; select &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; rbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; time&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;##             wbc        rbc       time
## wbc   1.0000000  1.0000000 -0.3294525
## rbc   1.0000000  1.0000000 -0.3294525
## time -0.3294525 -0.3294525  1.0000000&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;pairs&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/bivariate_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;categorical-variables&#34;&gt;Categorical variables&lt;/h2&gt;

&lt;p&gt;So far our focus has been on numerical variables. But what if we are working with categorical variables? When working with categorical variables we can either have two categorical variables or one categorical variable.&lt;/p&gt;

&lt;h3 id=&#34;categorical-and-quantitative&#34;&gt;Categorical and Quantitative&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s assume we have a categorical explanatory variable and a quantitative response variable.&lt;/p&gt;

&lt;p&gt;We will use the data from Cushny, A. R. and Peebles, A. R. (1905) The action of optical isomers: II hyoscines in &lt;code&gt;sleep&lt;/code&gt; data set.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;data&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;sleep&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
str&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;sleep&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## &amp;#39;data.frame&amp;#39;:    20 obs. of  3 variables:
##  $ extra: num  0.7 -1.6 -0.2 -1.2 -0.1 3.4 3.7 0.8 0 2 ...
##  $ group: Factor w/ 2 levels &amp;#34;1&amp;#34;,&amp;#34;2&amp;#34;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ ID   : Factor w/ 10 levels &amp;#34;1&amp;#34;,&amp;#34;2&amp;#34;,&amp;#34;3&amp;#34;,&amp;#34;4&amp;#34;,..: 1 2 3 4 5 6 7 8 9 10 ...&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We can see that our explanatory variable is &lt;code&gt;Group&lt;/code&gt;. Let&amp;rsquo;s say Group 1 is the control group 2 is the treatment group. Our response variable (Y-axis) is &lt;code&gt;extra&lt;/code&gt; sleep measured in hours.&lt;/p&gt;

&lt;p&gt;We can look at the statistics of the two groups:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;tapply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;sleep&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;extra&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; sleep&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;group&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kp&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## $`1`
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -1.600  -0.175   0.350   0.750   1.700   3.700 
## 
## $`2`
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -0.100   0.875   1.750   2.330   4.150   5.500&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;A more elegant way of doing this is to use the &lt;code&gt;dplyr&lt;/code&gt; package:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kn&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;dplyr&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
sleep &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
  group_by&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;group&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
  summarise&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;mean &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kp&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;extra&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; median &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; median&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;extra&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; sd &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; sd&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;extra&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; IQR &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; IQR&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;extra&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## # A tibble: 2 x 5
##   group  mean median    sd   IQR
##   &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1     0.750  0.350  1.79  1.88
## 2 2     2.33   1.75   2.00  3.28&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We can use graphical analysis to visualise the difference too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kn&#34;&gt;attach&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;sleep&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
boxplot&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;extra&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; group&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/bivariate_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can&amp;rsquo;t use scatterplot to visualise this however!&lt;/p&gt;

&lt;h3 id=&#34;categorical-and-catagorical-variable&#34;&gt;Categorical and Catagorical variable&lt;/h3&gt;

&lt;p&gt;In this case we can only compare the relative frequency and portions in each group. Let&amp;rsquo;s look at the data from case-control study of esophageal cancer in France:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;data&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;esoph&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
str&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;esoph&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## &amp;#39;data.frame&amp;#39;:    88 obs. of  5 variables:
##  $ agegp    : Ord.factor w/ 6 levels &amp;#34;25-34&amp;#34;&amp;lt;&amp;#34;35-44&amp;#34;&amp;lt;..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ alcgp    : Ord.factor w/ 4 levels &amp;#34;0-39g/day&amp;#34;&amp;lt;&amp;#34;40-79&amp;#34;&amp;lt;..: 1 1 1 1 2 2 2 2 3 3 ...
##  $ tobgp    : Ord.factor w/ 4 levels &amp;#34;0-9g/day&amp;#34;&amp;lt;&amp;#34;10-19&amp;#34;&amp;lt;..: 1 2 3 4 1 2 3 4 1 2 ...
##  $ ncases   : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ ncontrols: num  40 10 6 5 27 7 4 7 2 1 ...&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here &lt;code&gt;age group&lt;/code&gt; and &lt;code&gt;tobacco consumption (gm/day)&lt;/code&gt; are two categorical variables. We can tabulate these two:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;table1 &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kp&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;esoph&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;agegp&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; esoph&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;tobgp&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
table1&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;##        
##         0-9g/day 10-19 20-29 30+
##   25-34        4     4     3   4
##   35-44        4     4     4   3
##   45-54        4     4     4   4
##   55-64        4     4     4   4
##   65-74        4     4     4   3
##   75+          4     4     1   2&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We can ask the question &lt;strong&gt;what portion of 45 to 54 ages individuals smoke 20-29g of tobacco per day:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;prop.table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;table1&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;##        
##          0-9g/day     10-19     20-29       30+
##   25-34 26.666667 26.666667 20.000000 26.666667
##   35-44 26.666667 26.666667 26.666667 20.000000
##   45-54 25.000000 25.000000 25.000000 25.000000
##   55-64 25.000000 25.000000 25.000000 25.000000
##   65-74 26.666667 26.666667 26.666667 20.000000
##   75+   36.363636 36.363636  9.090909 18.181818&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We can see that 25% of the 45-54 years group smoke 20-29g per day.&lt;/p&gt;

&lt;p&gt;Question 2: &lt;strong&gt;Among those who smoke 20-29g per day, what percentage of them are 45 to 54 years of age?&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;prop.table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;table1&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;##        
##         0-9g/day    10-19    20-29      30+
##   25-34 16.66667 16.66667 15.00000 20.00000
##   35-44 16.66667 16.66667 20.00000 15.00000
##   45-54 16.66667 16.66667 20.00000 20.00000
##   55-64 16.66667 16.66667 20.00000 20.00000
##   65-74 16.66667 16.66667 20.00000 15.00000
##   75+   16.66667 16.66667  5.00000 10.00000&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;20% of those who smoke 20-29g per day, are 45-54 years old.&lt;/p&gt;

&lt;p&gt;Graphically we can use &lt;strong&gt;barplots&lt;/strong&gt; to analyse categorical variables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kn&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;ggplot2&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
ggplot&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;esoph&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; aes&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; agegp&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; fill &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; tobgp&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
  geom_bar&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/bivariate_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Univariate Analysis</title>
      <link>/post/statistics/eda/eda_univariate_analysis/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/statistics/eda/eda_univariate_analysis/</guid>
      
        <description>

&lt;p&gt;&lt;strong&gt;Univariate analysis&lt;/strong&gt; focuses on a unfolding the intrinsic statistics of a single variable at hand. This is done as the first step, before jumping into assessing the relationship between variables in our data set.&lt;/p&gt;

&lt;blockquote&gt;
&lt;div class=&#34;expand&#34;&gt;
    &lt;div class=&#34;expand-label&#34; style=&#34;cursor: pointer;&#34; onclick=&#34;$h = $(this);$h.next(&#39;div&#39;).slideToggle(100,function () {$h.children(&#39;i&#39;).attr(&#39;class&#39;,function () {return $h.next(&#39;div&#39;).is(&#39;:visible&#39;) ? &#39;fa fa-chevron-down&#39; : &#39;fa fa-chevron-right&#39;;});});&#34;&gt;
        &lt;i style=&#34;font-size:x-small;&#34; class=&#34;fa fa-chevron-right&#34;&gt;&lt;/i&gt;
        &lt;span&gt;
        
        
        Content
        
        &lt;/span&gt;
    &lt;/div&gt;
    &lt;div class=&#34;expand-content&#34; style=&#34;display: none;&#34;&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#data-type&#34;&gt;Data Type&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#measure-of-center&#34;&gt;Measure of Center&lt;/a&gt;&lt;br /&gt;
2.1. &lt;a href=&#34;#airthmatic-mean&#34;&gt;Arithmatic Mean&lt;/a&gt;&lt;br /&gt;
2.2. &lt;a href=&#34;#harmonic-and-geometric-mean&#34;&gt;Harmonic and Geometric Mean&lt;/a&gt;&lt;br /&gt;
2.3. &lt;a href=&#34;#median-&amp;amp;-mode&#34;&gt;Median and Mode&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#measure-of-spread&#34;&gt;Measure of Spread&lt;/a&gt;&lt;br /&gt;
3.1. &lt;a href=&#34;#variance&#34;&gt;Variance&lt;/a&gt;&lt;br /&gt;
3.2. &lt;a href=&#34;#coefficient-of-variance&#34;&gt;Coefficient of Variance&lt;/a&gt;&lt;br /&gt;
3.3. &lt;a href=&#34;#standard-deviation&#34;&gt;Standard Deviation&lt;/a&gt;&lt;br /&gt;
3.4. &lt;a href=&#34;#interquartile-range&#34;&gt;Interquartile Range&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#measure-of-skewness-and-kurtosis&#34;&gt;Measure of Skewness and Kurtosis&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#graphical-analysis&#34;&gt;Graphical Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;Univariate analyses can be divided into &lt;em&gt;graphical&lt;/em&gt; and &lt;em&gt;quantitative&lt;/em&gt; statistics. At the start of the analysis these two statistical procedures are best friends, by the end through they become inseparable lovers.&lt;/p&gt;

&lt;p&gt;Looking at the histogram without knowing the variability is pointless. So is calculating the variance without knowing how the sample distribution looks like.&lt;/p&gt;

&lt;p&gt;We will use R as our main statistical programming language and the &lt;code&gt;Leuk&lt;/code&gt; data set as an example.&lt;/p&gt;

&lt;h2 id=&#34;data-type&#34;&gt;Data Type&lt;/h2&gt;

&lt;p&gt;If we are given this data set and asked to perform a set of statistical tests, the first thing that should be identifying what type of data are we working with.&lt;/p&gt;

&lt;p&gt;Broadly speaking, we can expect the data set to be &lt;strong&gt;univariate&lt;/strong&gt; or a &lt;strong&gt;multivariate&lt;/strong&gt; which can be either &lt;strong&gt;numerical&lt;/strong&gt; or &lt;strong&gt;categorical&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Numerical

&lt;ul&gt;
&lt;li&gt;Discrete

&lt;ul&gt;
&lt;li&gt;e.g. shoe size&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Continuous

&lt;ul&gt;
&lt;li&gt;e.g. shoe length in cm&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Categorical

&lt;ul&gt;
&lt;li&gt;Nominal

&lt;ul&gt;
&lt;li&gt;e.g. group A, B, C&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ordinal

&lt;ul&gt;
&lt;li&gt;e.g. group A, B, C &lt;strong&gt;where&lt;/strong&gt; A &amp;gt; B &amp;gt; C&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kn&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;MASS&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
data&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;leuk&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# loading data set&lt;/span&gt;
str&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## &amp;#39;data.frame&amp;#39;:    33 obs. of  3 variables:
##  $ wbc : int  2300 750 4300 2600 6000 10500 10000 17000 5400 7000 ...
##  $ ag  : Factor w/ 2 levels &amp;#34;absent&amp;#34;,&amp;#34;present&amp;#34;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ time: int  65 156 100 134 16 108 121 4 39 143 ...&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We have 3 variables and 33 observation. White blood cell count and the survival time in weeks &lt;code&gt;time&lt;/code&gt; are numerical while &lt;code&gt;ag&lt;/code&gt; test result is categorical with two levels.&lt;/p&gt;

&lt;p&gt;Each row is a &lt;strong&gt;case&lt;/strong&gt; (or observation) and each column is a &lt;strong&gt;variable&lt;/strong&gt;, together they&amp;rsquo;re represented in a &lt;strong&gt;data matrix&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;##     wbc      ag time
## 1  2300 present   65
## 2   750 present  156
## 3  4300 present  100
## 4  2600 present  134
## 5  6000 present   16
## 6 10500 present  108&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;panel panel-primary&#34;&gt;
	
	&lt;div class=&#34;panel-body&#34;&gt;A &lt;strong&gt;data frame&lt;/strong&gt; in &lt;strong&gt;R&lt;/strong&gt; is a fundamental data structure that holds multiple variables of &lt;strong&gt;different type&lt;/strong&gt; together. In R a matrices can only hold data of the same family&lt;/div&gt;
	
&lt;/div&gt;


&lt;h2 id=&#34;measure-of-center&#34;&gt;Measure of Center&lt;/h2&gt;

&lt;p&gt;The three quantitative musketeers that point to the center are &lt;strong&gt;mean&lt;/strong&gt;, &lt;strong&gt;median&lt;/strong&gt; and &lt;strong&gt;Mode&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;airthmatic-mean&#34;&gt;Airthmatic Mean&lt;/h3&gt;

&lt;p&gt;Mean measures the center of the distribution. Mean is also known as the &lt;em&gt;expected value&lt;/em&gt; or the &lt;em&gt;central tendency&lt;/em&gt;, these terms are interchangeable however they&amp;rsquo;re  contextually used.&lt;/p&gt;

&lt;p&gt;For example, in our sample, the mean of WBC counts is the also the center of the WBC distribution. Expected value is the weighted mean however. In a very large sample, expected value would be the mean.&lt;/p&gt;

&lt;p&gt;We would use the term expected value when the problem is at the theoretical stage and the term mean when we actually have the data to calculate it. For a random variable &lt;code&gt;\(X\)&lt;/code&gt; where &lt;code&gt;\(x_i\)&lt;/code&gt; is a case and &lt;code&gt;\(f_i\)&lt;/code&gt; is its relative frequency, &lt;code&gt;\(mean\)&lt;/code&gt; is calculated as:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\large E(X) = \overline{x} = \frac{1}{N}\sum_{i=1}^{N}x_i = E(X) = \sum_{i=1}^{N}f_ix_i$$&lt;/code&gt;&lt;/p&gt;

&lt;div class=&#34;notices warning&#34; &gt;&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt; represent the summary from the &lt;em&gt;population&lt;/em&gt; whereas &lt;strong&gt;statistics&lt;/strong&gt; are &lt;em&gt;point estimates&lt;/em&gt; of those parameters obtained from the &lt;em&gt;sample&lt;/em&gt;. Parameters are represented by &lt;strong&gt;Greek&lt;/strong&gt; and point estimates by &lt;strong&gt;Roman&lt;/strong&gt; alphabets.&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt;&lt;code&gt;\(\large Parameter\ vs.\ statistics\ (point\ estimate)\ for\ population\ i:\)&lt;/code&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Parameter&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Statistic (point estimate)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(mean\)&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(\mu_i\)&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(\overline{x}\)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(standard\ deviation\)&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(\sigma_i\)&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(s_i\)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(proportion\)&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(P_i\)&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;code&gt;\(\hat{p}_i\)&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;harmonic-and-geometric-mean&#34;&gt;Harmonic and Geometric Mean&lt;/h3&gt;

&lt;p&gt;The arithmetic mean is heavily influenced by the extreme observations. To mitigate this problem, there are two famously known mathematical corrections that can be used:&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;harmonic mean&lt;/strong&gt; which is the reciprocal of the arithmetic mean of the reciprocals and the &lt;strong&gt;geometric mean&lt;/strong&gt; which is the arithmetic mean of the transformed variable:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\large \overline{X}_{H} = \frac{N}{\sum_{i=1}^{N} \frac{1}{x_i}} \\ \large \overline{X}_{G} = (x_i\ x_{i+1} ...x_n)^n = exp[\ ln(X_G)\ ]= exp[\  \frac{1}{N}\sum_{i=1}^{N}\ ln(x_i)\ ]$$&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;median-mode&#34;&gt;Median &amp;amp; Mode&lt;/h3&gt;

&lt;p&gt;Median is the value of the which is the the midpoint of the distribution while mode is the most likely (frequently occurring) value in the distribution.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at our Leukemia data set, focusing on WBC count:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 29165.15&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;median&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 10500&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;R does not have a built in function for mode, but that won&amp;rsquo;t stop us :D:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;mode &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kr&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  a &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kp&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
  a&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kp&#34;&gt;which.max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;a&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kp&#34;&gt;mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## 100000 
##      5&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;h2 id=&#34;measure-of-spread&#34;&gt;Measure of Spread&lt;/h2&gt;

&lt;p&gt;The spread of the distribution is another informative statistic that provides a better picture of the random variable of interest.&lt;/p&gt;

&lt;p&gt;Spread is the distance of individual observations ( &lt;code&gt;\(x_i\)&lt;/code&gt; ) from center of its distribution ( &lt;code&gt;\(\overline{x}\)&lt;/code&gt; ). Calculating the &lt;strong&gt;&lt;em&gt;variance&lt;/em&gt;&lt;/strong&gt; is one of the ways of communicating the dispersion in our distribution.&lt;/p&gt;

&lt;h3 id=&#34;variance&#34;&gt;Variance&lt;/h3&gt;

&lt;p&gt;Variance for variable &lt;code&gt;\(X\)&lt;/code&gt; is defined as:&lt;/p&gt;

&lt;p&gt;$$\large Var(X) =  E\ [\ (X-\mu)^2\ ] \ \large  $$&lt;/p&gt;

&lt;p&gt;This can be written as:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\large Var(X) = \frac{1}{N}\sum_{i = 1}^{N}\ [\ x_i - E(X)\ ]^2 = \sum_{i = 1}^{N}f_i[\ x_i - E(X)\ ]^2 = E(X^2) - (\overline{x})^2 = \sigma^2$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Variance is the difference between &lt;strong&gt;mean of squares&lt;/strong&gt; and the &lt;strong&gt;squared mean&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&#34;panel panel-primary&#34;&gt;
	&lt;div class=&#34;panel-heading&#34;&gt;Why the variability should be squared?&lt;/div&gt;
	&lt;div class=&#34;panel-body&#34;&gt;&lt;div class=&#34;expand&#34;&gt;
    &lt;div class=&#34;expand-label&#34; style=&#34;cursor: pointer;&#34; onclick=&#34;$h = $(this);$h.next(&#39;div&#39;).slideToggle(100,function () {$h.children(&#39;i&#39;).attr(&#39;class&#39;,function () {return $h.next(&#39;div&#39;).is(&#39;:visible&#39;) ? &#39;fa fa-chevron-down&#39; : &#39;fa fa-chevron-right&#39;;});});&#34;&gt;
        &lt;i style=&#34;font-size:x-small;&#34; class=&#34;fa fa-chevron-right&#34;&gt;&lt;/i&gt;
        &lt;span&gt;
        
        
        
        
        &lt;/span&gt;
    &lt;/div&gt;
    &lt;div class=&#34;expand-content&#34; style=&#34;display: none;&#34;&gt;
&lt;p&gt;Let&amp;rsquo;s take a look at an example &lt;code&gt;\(A = (2, 3, 4, 5)\)&lt;/code&gt;. &lt;code&gt;\(E(A) = 3.5\)&lt;/code&gt;, if we would like to measure the overall dispersion in this set we would get &lt;code&gt;\((2 - 3.5) + (3 - 3.5) + (4 - 3.5) + (5 - 3.5)\)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Do you see the problem? &lt;code&gt;\(-1.5 - 0.5 +0.5 + 1.5 = 0\)&lt;/code&gt;. To workaround the problem we&amp;rsquo;d square all the terms &lt;code&gt;\(E(A)^2 = 12.25\)&lt;/code&gt;.
&lt;code&gt;\(\frac{1}{4}[(2 - 3.5)^2 + (3 - 3.5)^2 + (4 - 3.5)^2 + (5 - 3.5)^2] = 1.25\)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We will also get the same result if we follow the other formula:
&lt;code&gt;\(\frac{1}{4}[(4 - 12.25) +  (9 - 12.25) + (16 - 12.25) + (25 - 12.25)] = 1.25\)&lt;/code&gt;
Also:
&lt;code&gt;\(E(X^2) - (\overline{x})^2 = \frac{1}{4}(4+9+16+25) - 3.5^2 = 1.25\)&lt;/code&gt;&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
	
&lt;/div&gt;


&lt;h3 id=&#34;coefficient-of-variance&#34;&gt;Coefficient of Variance&lt;/h3&gt;

&lt;p&gt;When considering comparing the variability in two nonidentical and heterogeneous population, comparing variances may be misleading. &lt;strong&gt;Coefficient of variance&lt;/strong&gt; allows for a true comparison. For a random variable X, CV is defined as:&lt;/p&gt;

&lt;p&gt;$$\large CV[X] = \frac{\sigma}{\mu}\times 100\% $$&lt;/p&gt;

&lt;p&gt;CV is a consistent measurement of spread as it measures variability unitlessly.&lt;/p&gt;

&lt;div class=&#34;expand&#34;&gt;
    &lt;div class=&#34;expand-label&#34; style=&#34;cursor: pointer;&#34; onclick=&#34;$h = $(this);$h.next(&#39;div&#39;).slideToggle(100,function () {$h.children(&#39;i&#39;).attr(&#39;class&#39;,function () {return $h.next(&#39;div&#39;).is(&#39;:visible&#39;) ? &#39;fa fa-chevron-down&#39; : &#39;fa fa-chevron-right&#39;;});});&#34;&gt;
        &lt;i style=&#34;font-size:x-small;&#34; class=&#34;fa fa-chevron-right&#34;&gt;&lt;/i&gt;
        &lt;span&gt;
        
        
        Example: Application of CV in Applied Science
        
        &lt;/span&gt;
    &lt;/div&gt;
    &lt;div class=&#34;expand-content&#34; style=&#34;display: none;&#34;&gt;
&lt;div class=&#34;panel panel-primary&#34;&gt;
    
    &lt;div class=&#34;panel-body&#34;&gt;&lt;p&gt;Suppose we would like to compare the average cholesterol levels in Americans with Australians.
Suppose the American population has a mean of 14.0 mg/dl with standard deviation of 7.0 mg/dl; and the average cholesterol level in Australian is 3.8  with standard deviation of 0.6mmol/l.&lt;/p&gt;

&lt;p&gt;Instead of converting these values we can instead use CV: 50% vs 15.8%. American population seems far more heterogeneous.&lt;/p&gt;
&lt;/div&gt;
    

&lt;p&gt;&lt;/div&gt;&lt;/p&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;standard-deviation&#34;&gt;Standard Deviation&lt;/h3&gt;

&lt;p&gt;The standard deviation is the square root of the variance. It is also equivalent to the commonly used &lt;strong&gt;root-mean-square error (RMSE)&lt;/strong&gt;. Standard deviation gives a good estimate of how close the data is to the center of the distribution.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\large \sigma = \sqrt{Var(X)}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;An important point to make here is to make a note of the symbols! This formula is valid only if we are dealing with &lt;strong&gt;population parameters&lt;/strong&gt; ( &lt;code&gt;\(\large \sigma_x\neq s_x\)&lt;/code&gt; ).&lt;/p&gt;

&lt;p&gt;For a sample of population &lt;code&gt;\(X\)&lt;/code&gt; we calculate sigma with a &lt;em&gt;degree of freedom&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\large s_x^2 = \frac{1}{N}\sum_{i=1}^{N}(x_i-\overline{x})^2$$&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;empirical-68-95-and-99-7-rule&#34;&gt;Empirical 68, 95 and 99.7 Rule&lt;/h4&gt;

&lt;p&gt;Depending on the distribution, the spread of the data would follow the &lt;strong&gt;68, 95 and 99.7 rule&lt;/strong&gt;. That is 68% of the data would fall in &lt;code&gt;\(\large \overline{x} \pm s\)&lt;/code&gt;, 95% within &lt;code&gt;\(\large \overline{x} \pm 2s\)&lt;/code&gt; and 99.7% within &lt;code&gt;\(\large \overline{x} \pm 3s\)&lt;/code&gt;. This is a rough estimation however. The actual multiplier of the &lt;code&gt;\(s\)&lt;/code&gt; depends on the critical value of the distribution. For example, in a &lt;code&gt;\(\large z-distribution\)&lt;/code&gt; this would be &lt;code&gt;\(\large \overline{x} \pm z^ \star s\)&lt;/code&gt; and for 95% confidence interval &lt;code&gt;\(\large z^\star = 1.96\)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/statistics/68-95-997.jpg&#34; alt=&#34;&#34; width=&#34;500px&#34; height=&#34;400px&#34;/&gt;&lt;/p&gt;

&lt;h3 id=&#34;interquartile-range&#34;&gt;Interquartile Range&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Range&lt;/strong&gt; is the most basic measurement of variability in data. A numerical variable ranges from &lt;code&gt;\(min(x)\)&lt;/code&gt; to &lt;code&gt;\(max(x)\)&lt;/code&gt;. Range alone is not very helpful however &lt;strong&gt;interquartile range&lt;/strong&gt; is! IQR tells us the variabilit for the middle 50% of data. The larger the standard deviation the larger the IQR.
&lt;code&gt;$$range = max(x) - min(x) \\ \ \\ Q_3 = \frac{max_x - median_x}{2} \\ \ \\ Q_1 = \frac{median_x - min_x}{2} \\ \ \\ IQR = Q_3 - Q_1$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Outliers&lt;/strong&gt; can be identified using the IQR. Any case that falls out of &lt;code&gt;\(Q_1 - 1.5IQR\ or Q_3 + 3IQR\)&lt;/code&gt; is considered an outlier.&lt;/p&gt;

&lt;h2 id=&#34;measure-of-skewness-and-kurtosis&#34;&gt;Measure of Skewness and Kurtosis&lt;/h2&gt;

&lt;p&gt;We can&amp;rsquo;t really talk about skewness and kurtosis without looking at the data. &lt;strong&gt;Rule of thumb&lt;/strong&gt;: always look at the data! - we&amp;rsquo;ll get into graphical analysis later on.&lt;/p&gt;

&lt;p&gt;Skewness is a measure of asymmetry and kurtosis measures the degree of peakedness. Looking at the WBC count in our &lt;code&gt;leuk&lt;/code&gt; data set, the distribution of WBC counts seems to be &lt;strong&gt;bimodal&lt;/strong&gt; (kurtosis) with a long &lt;strong&gt;right tail&lt;/strong&gt; (kurtosis).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;hist&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; breaks &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/univariate_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at why quantitative and graphical analyses should always be carried out together.&lt;/p&gt;

&lt;p&gt;Suppose we have two samples, &lt;code&gt;\(\overline{x}_{1\&amp;amp;2} =  0.6923\ ; s_{1\&amp;amp;2} = 0.1685\)&lt;/code&gt;. Looking at the statistics alone, our samples seem similar if not identical! However, they each belong to a different Beta distribution!&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;set.seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9999&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
x&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;rnorm&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;x&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.1685&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;kp&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;sd&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;+0.6923&lt;/span&gt;

curve&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;dbeta&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; xlim &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# sample 1&lt;/span&gt;
curve&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;dbeta&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.3846&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; x&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; add &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; col &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;red&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#sample 2 = red&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/univariate_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;div class=&#34;expand&#34;&gt;
    &lt;div class=&#34;expand-label&#34; style=&#34;cursor: pointer;&#34; onclick=&#34;$h = $(this);$h.next(&#39;div&#39;).slideToggle(100,function () {$h.children(&#39;i&#39;).attr(&#39;class&#39;,function () {return $h.next(&#39;div&#39;).is(&#39;:visible&#39;) ? &#39;fa fa-chevron-down&#39; : &#39;fa fa-chevron-right&#39;;});});&#34;&gt;
        &lt;i style=&#34;font-size:x-small;&#34; class=&#34;fa fa-chevron-right&#34;&gt;&lt;/i&gt;
        &lt;span&gt;
        
        
        Code
        
        &lt;/span&gt;
    &lt;/div&gt;
    &lt;div class=&#34;expand-content&#34; style=&#34;display: none;&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;dbeta&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 1.637482&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;dbeta&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.3846&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; x&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 1.680538&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;sd&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;dbeta&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 0.6498106&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;sd&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;dbeta&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.3846&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; x&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;4.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 0.6410224&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The parameters don&amp;rsquo;t differ much! However, looking at the Beta distribution plots, they are the opposite of each other.&lt;/p&gt;

&lt;h3 id=&#34;skewness&#34;&gt;Skewness&lt;/h3&gt;

&lt;p&gt;Mathematically skewness ( &lt;code&gt;\(\large \gamma_1\)&lt;/code&gt; )is defined as:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\large {\gamma_1 = \frac{\mu_3}{\mu_2^\frac{3}{2}}= \frac{\mu_3}{\sigma^3}}$$&lt;/code&gt;
Where:
$$ {{\mu_1 = 0 \ \mu_2 = E\ [\ (X - \mu)\ ] = \sigma^2 \ \mu_3 = E\ [\ (X - \mu)^2\ ] = \sigma^3\gamma_1}}$$&lt;/p&gt;

&lt;p&gt;Distinction between population and sample:
&lt;code&gt;$$\gamma_{1} = \sqrt{n} \frac{\sum_{i =1}^{n}(X_i-\mu)^3}{[\ \sum_{i =1}^{n}(X_i-\mu)^2\ ]^{3/2}} \\ \ \\ g_1 = \frac{n \sqrt{n-1}}{n-2} \times \frac{\sum_{i =1}^{n}(X_i-\mu)^3}{[\ \sum_{i =1}^{n}(X_i-\mu)^2\ ]^{3/2}}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\(\mu_3\)&lt;/code&gt; and &lt;code&gt;\(\mu_2\)&lt;/code&gt; are called &lt;strong&gt;third and second moment&lt;/strong&gt; of data.&lt;/p&gt;

&lt;h3 id=&#34;kurtosis&#34;&gt;Kurtosis&lt;/h3&gt;

&lt;p&gt;Kurtosis is the &lt;strong&gt;forth moment&lt;/strong&gt; of data. Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution. therefore, the outliers in a sample heavily influence the kurtosis. In a symmetric distribution with long tails on both sides, the tails offset each other while they both increase the kurtosis.&lt;/p&gt;

&lt;p&gt;In other words, datasets with high kurtosis tend to have outliers and vice versa.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\large \mu_4 = E\ [\ (X - \mu)^3\ ] = \sigma^4\gamma_2 \\ \large \gamma_2 = \frac{\mu_4}{\mu_2^2} = \frac{\mu_4}{(\sigma^2)^2}$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Again the difference in population and sample is:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$$\gamma_2 = n \times \frac{\sum_{i =1}^{n}(X_i-\mu)^4}{[\ \sum_{i =1}^{n}(X_i-\mu)^2\ ]^{2}}
\\
k = \frac{n(n+1)(n-1)}{(n-2)(n-3)} \times \frac{\sum_{i =1}^{n}(X_i-\mu)^4}{[\ \sum_{i =1}^{n}(X_i-\mu)^2\ ]^{2}}$$&lt;/code&gt;&lt;/p&gt;

&lt;div class=&#34;panel panel-primary&#34;&gt;
	
	&lt;div class=&#34;panel-body&#34;&gt;&lt;p&gt;&lt;strong&gt;Robust statistics&lt;/strong&gt; are statistical measures that are not affected by the outliers, skewness and kurtosis of the distribution. Mean and standard deviation are &lt;strong&gt;not&lt;/strong&gt; robust statistics. &lt;strong&gt;Median&lt;/strong&gt; and &lt;strong&gt;IQR&lt;/strong&gt; are robust as they resist the influence of outliers.&lt;/p&gt;

&lt;div class=&#34;expand&#34;&gt;
    &lt;div class=&#34;expand-label&#34; style=&#34;cursor: pointer;&#34; onclick=&#34;$h = $(this);$h.next(&#39;div&#39;).slideToggle(100,function () {$h.children(&#39;i&#39;).attr(&#39;class&#39;,function () {return $h.next(&#39;div&#39;).is(&#39;:visible&#39;) ? &#39;fa fa-chevron-down&#39; : &#39;fa fa-chevron-right&#39;;});});&#34;&gt;
        &lt;i style=&#34;font-size:x-small;&#34; class=&#34;fa fa-chevron-right&#34;&gt;&lt;/i&gt;
        &lt;span&gt;
        
        
        Example:
        
        &lt;/span&gt;
    &lt;/div&gt;
    &lt;div class=&#34;expand-content&#34; style=&#34;display: none;&#34;&gt;
&lt;p&gt;Let&amp;rsquo;s look at this set:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;x &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; rnorm&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
x2 &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# with an outlier, i.e. value 100&lt;/span&gt;

&lt;span class=&#34;kp&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 5.065149&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;kp&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x2&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# notice the large increase&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 6.005098&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;sd&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 1.861745&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;sd&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x2&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# HUGE increase!&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 9.626285&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;median&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 4.762738&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;median&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x2&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# robust measure of the centre&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 4.822391&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;IQR&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 2.179584&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;IQR&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;x2&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# robust measure of variability&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;## [1] 2.238293&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
	
&lt;/div&gt;


&lt;h2 id=&#34;graphical-analysis&#34;&gt;Graphical Analysis&lt;/h2&gt;

&lt;p&gt;In terms of graphical representation of a single variable, we can only hope to see the variability and the center of our distribution. There are only few graphical techniques that can help us:&lt;/p&gt;

&lt;h3 id=&#34;dot-plot&#34;&gt;Dot plot&lt;/h3&gt;

&lt;p&gt;A dot plot presents numerical data point as a single dot along a single aix . We have the option of stacking each point or have it scattered.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;stripchart&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; method &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;stack&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/univariate_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;stripchart&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/univariate_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;box-plot&#34;&gt;Box plot&lt;/h3&gt;

&lt;p&gt;A box plot utilizes the range to represent the median, Q1, Q2, Q3 and Q4 as well as the upper and lower limit (1.5IQR) with whiskers. Any observation that falls beyond the whiskers is therefore an outlier.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;boxplot&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; horizontal &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/univariate_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see two cases to be potential outliers.&lt;/p&gt;

&lt;h3 id=&#34;histogram&#34;&gt;Histogram&lt;/h3&gt;

&lt;p&gt;For small samples, dot plots are useful as they show the exact value of each point. However if we have a relatively large sample size dot plots are impractical. Histograms display &lt;strong&gt;data density&lt;/strong&gt; of &lt;strong&gt;binned&lt;/strong&gt; data poins. Bins collect all points that fall within a specified width.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;hist&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;leuk&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;wbc&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; breaks &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#breaks defines how many bins should be shown.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/eda/univariate_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Probability Function</title>
      <link>/post/statistics/probability/probability_function/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/statistics/probability/probability_function/</guid>
      
        <description>&lt;p&gt;Probability function is the function of a random variable distribution, whose value provides the &lt;em&gt;absolute&lt;/em&gt; or &lt;em&gt;relative likelihood&lt;/em&gt; of the value of the random variable in the sample.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Depending on the &lt;em&gt;type&lt;/em&gt; of our random variable, we can calculate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Absolute likelihood&lt;/strong&gt; for a &lt;u&gt;discrete variable&lt;/u&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Relative likelihood&lt;/strong&gt; for a &lt;u&gt;continuous variable&lt;/u&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On this page we will discuss:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#probability-mass-function&#34;&gt;Probability Mass Function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#probability-density-function&#34;&gt;Probability Density Function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pmfs-and-pdfs&#34;&gt;Popular PMFs and PDFs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;probability-mass-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Probability Mass Function&lt;/h2&gt;
&lt;p&gt;Discrete random variables have discrete and countable values. That &lt;strong&gt;PMF&lt;/strong&gt; tells us the probability that the random variable takes each of the possible values.&lt;/p&gt;
&lt;p&gt;Assume a simple random experiment of coin toss where a &lt;strong&gt;fair&lt;/strong&gt; coin is tossed twice. let &lt;span class=&#34;math inline&#34;&gt;\(X =\)&lt;/span&gt; number of tails we get:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(S = {(HH),(TH),(HT),(TT)}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;P(X = 0) = (HH)&lt;/li&gt;
&lt;li&gt;P(X = 1) = (HT) or (TH)&lt;/li&gt;
&lt;li&gt;P(X = 2) = (TT)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here we can use a binomial distribution to calcualte the &lt;strong&gt;absolute&lt;/strong&gt; likelihood of (X = 2); using the Probability Mass Function formula for binomial distribution:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P\left(X = k~|~~ n = n, p= p\right) = \left(\begin{array}{c} n\\k \end{array}\right) ~ p^k ~ (1-p)^{n-k}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here we can calculate the P(X = k) for each outcome:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dbinom(0, 2, 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.25&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dbinom(1, 2, 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dbinom(2, 2, 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.25&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can visualise &lt;em&gt;Probability Mass Function&lt;/em&gt; using historframs. Let’s Visualise what will happen if we repeat this experiment 1000 times:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Two_cointosses_1000_times = sample(x=c(&amp;quot;HH&amp;quot;,&amp;quot;HT&amp;quot;,&amp;quot;TT&amp;quot;), size=1000, replace = T, prob=c(.25,.50,.25))
barplot(table(Two_cointosses_1000_times))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/probability/probability_function_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The area under the histogram is one and the area of each bar is the probability of seeing a binomial random variable, whose value is equal to the x-value at the center of the bars base.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;probability-density-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Probability Density Function&lt;/h2&gt;
&lt;p&gt;In contrast, the normal distribution also called the &lt;em&gt;Gaussian&lt;/em&gt; distribution can take any numerical value between negative infinity and positive infinity. Since it can take a continuum of values,it is a continuous random variable.&lt;/p&gt;
&lt;p&gt;Consider random variable X = foot length of adult males. Unlike shoe size, this variable is not limited to distinct, separate values (i.e. It is not discrete), because foot lengths can take any value over a continuous range of possibilities, so we cannot present this variable with a probability histogram or a table.&lt;/p&gt;
&lt;p&gt;The probability distribution of foot length (or any other continuous random variable) can be represented by a smooth curve called a &lt;strong&gt;probability density curve&lt;/strong&gt;. &lt;img src=&#34;/probability/pdf.gif&#34; /&gt; The total area under the density curve equals 1, and the curve represents probabilities by area.&lt;/p&gt;
&lt;p&gt;When the random variable is continuous, it has &lt;em&gt;probability zero of taking any single value&lt;/em&gt;, &lt;span class=&#34;math inline&#34;&gt;\(P(X =x) =0\)&lt;/span&gt;. Here we can only talk about the &lt;strong&gt;relative likelihood&lt;/strong&gt; of the continuous random variable &lt;em&gt;within some interval&lt;/em&gt;. Continuous random variables have &lt;strong&gt;probability density functions&lt;/strong&gt; or pdfs instead of probability mass functions. &lt;img src=&#34;/probability/pdf2.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The PDF curve of a random variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(M =\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(SD = \sigma\)&lt;/span&gt;: &lt;span class=&#34;math display&#34;&gt;\[\large f(x)=\frac{1}{\sigma\sqrt{2\pi}}~\times~ e^{\LARGE[-\frac{1}{2\pi^2}\times(x-\mu)^2]} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here the area under the curve, or the &lt;strong&gt;density&lt;/strong&gt; would be: &lt;span class=&#34;math display&#34;&gt;\[ P( a \leq x \leq b) = \int_{a}^{b}f(x)dx\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pmfs-and-pdfs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;PMFs and PDFs&lt;/h2&gt;
&lt;p&gt;There are many types of PMFs and PDFs, here are a handful of most famous distributions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Discrete (&lt;em&gt;PMF&lt;/em&gt;)
&lt;ul&gt;
&lt;li&gt;Binomial&lt;/li&gt;
&lt;li&gt;Poisson&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Continuous (&lt;em&gt;PDF&lt;/em&gt;)
&lt;ul&gt;
&lt;li&gt;Normal distribution&lt;/li&gt;
&lt;li&gt;Uniform&lt;/li&gt;
&lt;li&gt;Beta&lt;/li&gt;
&lt;li&gt;Gamma&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>/about/</guid>
      
        <description>&lt;p&gt;Hugo is a static site engine written in Go.&lt;/p&gt;

&lt;p&gt;It makes use of a variety of open source projects including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cobra&#34;&gt;Cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;Viper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/jWalterWeatherman&#34;&gt;J Walter Weatherman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cast&#34;&gt;Cast&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Exploratory Data Analysis (introduction)</title>
      <link>/post/statistics/eda/eda_introduction/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/statistics/eda/eda_introduction/</guid>
      
        <description>&lt;p&gt;Exploratory data analysis (EDA) is an approach to data analysis that employs tools of descriptive statistics in order to dissect the data. the term &lt;em&gt;exploratory data analysis&lt;/em&gt; was coind by John W. Tukey in the 70s.&lt;/p&gt;

&lt;p&gt;EDA is a philosophy rather than being statistical technique, in which the statistician takes the role of a detective whose main goal is to unveil the underlying patterns. This is contrary to the classical statistician who acts as a judge instaed.&lt;/p&gt;

&lt;p&gt;EDA analyses starts with descriptive statistics as the starting point for hypothesis formation and modelling.&lt;/p&gt;

&lt;p&gt;The sequence of events hence can be summarised as:&lt;/p&gt;

&lt;link href=&#34;/mermaid/mermaid.css&#34; type=&#34;text/css&#34; rel=&#34;stylesheet&#34;/&gt;
&lt;script defer src=&#34;/mermaid/mermaid.js&#34;&gt;mermaid.initialize({startOnLoad:true});&lt;/script&gt;
&lt;div class=&#34;mermaid&#34; align=&#34;center&#34; &gt;
graph LR;
    A[Population of interest] --&gt; B[Sampling]
    B --&gt;C(Data)
&lt;/div&gt;

&lt;link href=&#34;/mermaid/mermaid.css&#34; type=&#34;text/css&#34; rel=&#34;stylesheet&#34;/&gt;
&lt;script defer src=&#34;/mermaid/mermaid.js&#34;&gt;mermaid.initialize({startOnLoad:true});&lt;/script&gt;
&lt;div class=&#34;mermaid&#34; align=&#34;center&#34; &gt;
graph LR;
    A(Data) --&gt; |EDA| B{Analysis}
    A --&gt; C((Model &lt;br&gt; imposition))
    C --&gt; |Bayesian|D(Prior probability &lt;br&gt; or distribution)
    C --&gt; |Frequentist|B
    D --&gt; B
    B --&gt; |EDA|E((Inferential &lt;br&gt; modeling))
    B --&gt; |Bayesian and &lt;br&gt; Frequenstist|F(Conclusion)
    E --&gt; F

&lt;/div&gt;

&lt;link href=&#34;/mermaid/mermaid.css&#34; type=&#34;text/css&#34; rel=&#34;stylesheet&#34;/&gt;
&lt;script defer src=&#34;/mermaid/mermaid.js&#34;&gt;mermaid.initialize({startOnLoad:true});&lt;/script&gt;
&lt;div class=&#34;mermaid&#34; align=&#34;center&#34; &gt;
graph LR;  
    H(Conclusion) -.-&gt; |Bayesian|G[Updating priori &lt;br&gt; using the posteriori]
    
&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>2018 04 11 Wer</title>
      <link>/post/blog/2018-04-11-wer/</link>
      <pubDate>Wed, 11 Apr 2018 11:55:32 +1000</pubDate>
      
      <guid>/post/blog/2018-04-11-wer/</guid>
      
        <description>&lt;p&gt;Lorem Ipsum.
Notice &lt;code&gt;draft&lt;/code&gt; is set to true.
asdasd&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Beta Distribution</title>
      <link>/post/statistics/probability/continuous-probability-distributions/beta-distribution/</link>
      <pubDate>Mon, 12 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/statistics/probability/continuous-probability-distributions/beta-distribution/</guid>
      
        <description>&lt;p&gt;We’ll introduce the beta distribution by using an example:&lt;/p&gt;
&lt;div id=&#34;example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://ghr.nlm.nih.gov/condition/diamond-blackfan-anemia&#34;&gt;Diamond Blackfan anemia (DBA)&lt;/a&gt; is a rare autosomal dominant bone marrow disease. Children with Diamond Blackfan anemia present with symptoms of extreme anemia during the first year of life.&lt;/p&gt;
&lt;p&gt;Unfortunately, patients have an increased risk of other serious bone marrow malfunctions. Specifically, they are prone to developing myelodysplastic syndrome (MDS), certain blood cancers such as acute myeloid leukemia (AML) and bone cancer (osteosarcoma).&lt;/p&gt;
&lt;p&gt;At &lt;a href=&#34;http://diablo.wikia.com/wiki/Harrogath&#34;&gt;Harrogath&lt;/a&gt; the prevalence of DBA is exceptionally high (5 in 1000). Harrogathian scientists have teamed up with Kehjistanian scientists to study the probability of developing cancer in DBA patients based on their initial LDH level.&lt;/p&gt;
&lt;p&gt;Kehjistanian scientists have a studied the tendency of DBA to develop into cancers before. Therefore, here we have the luxuary of using Bayesian statistics to update what we already know about the LDH and cancer development.&lt;/p&gt;
&lt;p&gt;** How can we use describe the &lt;em&gt;prior probability&lt;/em&gt; in a meaningful way? **&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;beta-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beta distribution&lt;/h2&gt;
&lt;p&gt;The Beta density function is a versatile way to represent continuous outcomes like proportions or probabilities that lie between 0 and 1.&lt;/p&gt;
&lt;p&gt;The Beta can be used to describe not only the variety observed across sample, but it can also describe your &lt;strong&gt;subjective degree of belief&lt;/strong&gt; (in a Bayesian sense). If you are not entirely sure that the probability is 0.22, but rather you think that is the most likely value but that there is some chance that the value is higher or lower, then maybe your personal beliefs can be described as a Beta distribution.&lt;/p&gt;
&lt;p&gt;Let’s say based on previous studies, we know the mean percentage increase in LDH level and standard deviation is &lt;span class=&#34;math inline&#34;&gt;\(\mu = 0.55\)&lt;/span&gt; &amp;amp; &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.09\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;beta&lt;/em&gt; distribution is defined by two parameters &lt;span class=&#34;math inline&#34;&gt;\(\alpha ~&amp;amp;~ \beta\)&lt;/span&gt;, the &lt;strong&gt;probability density function&lt;/strong&gt; of beta distribution is defined as: &lt;span class=&#34;math display&#34;&gt;\[\Large B(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha +\beta)}\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[Note:~\Gamma(k)=(k-1)!\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The values of alpha and beta can be derived from the sample: &lt;span class=&#34;math display&#34;&gt;\[\large E(x)=\mu=\frac{\alpha}{\alpha+\beta}\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[\large Variance(x)=\sigma^2=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)} \]&lt;/span&gt; Here are some examples of beta distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;curve( dbeta(x,1,1), xlim=c(0,1), ylim=c(0,4) )
curve( dbeta(x,0.5,0.5), add=T, col=&amp;#39;red&amp;#39; )
curve( dbeta(x,5,1), add=T, col=&amp;#39;green&amp;#39; )
curve( dbeta(x,1,3), add=T, col=&amp;#39;blue&amp;#39; )
title(main=&amp;quot;Beta distribution&amp;quot;)
legend(par(&amp;#39;usr&amp;#39;)[1], par(&amp;#39;usr&amp;#39;)[4], xjust=-1.9,
       c(&amp;#39;(1,1)&amp;#39;, &amp;#39;(0.5,0.5)&amp;#39;, &amp;#39;(5,1)&amp;#39;, &amp;#39;(1,3)&amp;#39;), 
      
       lwd=1, #c(1,1,1,1, 2,2,2, 3,3,3),
       lty=c(1,1,1,1, 2,2,2, 3,3,3),
       col=c(par(&amp;#39;fg&amp;#39;), &amp;#39;red&amp;#39;, &amp;#39;green&amp;#39;, &amp;#39;blue&amp;#39; ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/statistics/probability/continuous-probability-distributions/beta_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example&lt;/h3&gt;
&lt;p&gt;Back to our example: &lt;span class=&#34;math display&#34;&gt;\[ E(x) = \mu = 0.55 =\frac{\alpha}{\alpha+\beta}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Variance(x)=\sigma^2= 0.09^2=0.0081=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[From~the~first~equation~we~have: \beta = \frac{\alpha}{0.55}-\alpha = 0.82\alpha ~~~and~~~\alpha=\frac{0.55\beta}{1-0.55} = 1.22\beta \]&lt;/span&gt; After simple algebra using beta in the second equation we’ll get:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ 0.79\alpha^2 - 0.049\alpha^3 = 0 \]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[  1.18\beta^2 - 0.089\beta^3 = 0 \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(polynom)
beta = polyroot(z = c(0, 0, 1.18, -0.089)) # z is a vector of polynomial coefficients in increasing order: x^0, X^1 ...
beta # only the 3rd value is not 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  0.00000+0i  0.00000+0i 13.25843+0i&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta = abs(beta[3])

alpha = polyroot(z = c(0, 0, 0.79, -0.049))
alpha #we choose the 3rd&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  0.00000+0i  0.00000+0i 16.12245+0i&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha = abs(alpha[3])&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 16.12245&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13.25843&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;curve( dbeta(x,alpha,beta) )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/statistics/probability/continuous-probability-distributions/beta_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Please use &lt;code&gt;Wolfram Alpha math engine&lt;/code&gt; to solve the equations.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>Discrete Probability Distribution</title>
      <link>/post/statistics/probability/probability_discrete_distribution/</link>
      <pubDate>Mon, 12 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/statistics/probability/probability_discrete_distribution/</guid>
      
        <description>&lt;p&gt;Probability distributions demonstrate the probability of an event. When dealing with discrete data, &lt;strong&gt;probability mass function&lt;/strong&gt; of the &lt;em&gt;event&lt;/em&gt; can come from various distributions. The most important discrete probability distributions are the &lt;strong&gt;Bernoulli&lt;/strong&gt;, &lt;strong&gt;Binomial&lt;/strong&gt; and &lt;strong&gt;Poisson&lt;/strong&gt;.&lt;/p&gt;
&lt;!--more--&gt;
&lt;hr /&gt;
&lt;div id=&#34;bernoulli-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bernoulli distribution&lt;/h2&gt;
&lt;p&gt;The most widely known &lt;em&gt;unknown&lt;/em&gt; discrete probability distribution is the &lt;strong&gt;Bernoulli distribution&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Named after the Swiss mathematician &lt;a href=&#34;https://en.wikipedia.org/wiki/Jacob_Bernoulli&#34;&gt;Jacob Bernoulli&lt;/a&gt;, the Bernoulli distribution is the probability distribution of the outcome of a single experiment with two possible outcomes. Each outcome is a Boolean-valued discrete random variable (&lt;em&gt;k=1&lt;/em&gt; or &lt;em&gt;k=0&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Unlike the binomial distribution, the Bernoulli distribution is used in &lt;strong&gt;single trial (n=1)&lt;/strong&gt; experiments. This is a special case of the Binomial distribution where a single experiment/trial is conducted (n=1).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is a discrete random variable that belongs to the Bernoulli distribution if: &lt;span class=&#34;math display&#34;&gt;\[ P(X=1) = p = 1 - P(X = 0) = 1 - q \]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;bernoulli-probability-mass-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bernoulli Probability Mass Function&lt;/h3&gt;
&lt;p&gt;The probability mass function can be written as: &lt;span class=&#34;math display&#34;&gt;\[f(k;p) = \left\{ \begin{array}{lcl}p &amp;amp;\mbox{if}&amp;amp;k=1 \\ 1-p &amp;amp;\mbox{if}&amp;amp;k=0 \end{array} \right.\]&lt;/span&gt; Can be expressed as: &lt;span class=&#34;math display&#34;&gt;\[f(k;p) = p^k(1-p)^{1-k} ~for~k\in \{0,1\}  \]&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;A &lt;strong&gt;binomial variable&lt;/strong&gt; of parameters (n,p) is the &lt;strong&gt;sum of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; Bernoulli variables&lt;/strong&gt; of parameter p.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;example&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Example&lt;/h4&gt;
&lt;p&gt;While focusing on locating the NPHLM gene, the &lt;a href=&#34;http://diablo.wikia.com/wiki/Kehjistan&#34;&gt;Kehjistanian&lt;/a&gt; scientists also discovered that, for any given birth at any given day, there is a fixed 0.60 chance that the newborn is a female.&lt;/p&gt;
&lt;p&gt;If on average there is one birth every 2 minutes, what is the projected population of males in Caldeum over 20 years?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n = (60*24*365*20)/2
x = sample(c(0,1), n, replace=T, prob=c(.6,.4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(cumsum(x), type=&amp;#39;l&amp;#39;,
     main=&amp;quot;Cummulative sums of males (a Bernoulli variable)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/probability/pmf_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;binomial-distribution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Binomial distribution&lt;/h2&gt;
&lt;p&gt;The binomial distribution describes the probability of having exactly &lt;strong&gt;&lt;em&gt;k&lt;/em&gt;&lt;/strong&gt; successes in &lt;strong&gt;&lt;em&gt;n&lt;/em&gt;&lt;/strong&gt; independent Bernoulli trials, given that the probability of &lt;em&gt;k = 1&lt;/em&gt; is &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;&lt;/strong&gt;. It is important to note that the success rate of the binary event remains constant for all n independent trials.&lt;/p&gt;
&lt;p&gt;To use a binomial distribution, data must come from a &lt;strong&gt;binomial experiment&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; = fixed number of trials&lt;/li&gt;
&lt;li&gt;Trials must be &lt;strong&gt;independent&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Each trial has &lt;strong&gt;two possible outcome&lt;/strong&gt; where:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;P&lt;/em&gt;(sucess) = constant for each trial&lt;/li&gt;
&lt;li&gt;&lt;em&gt;P&lt;/em&gt;(failure) = 1 - &lt;em&gt;P&lt;/em&gt;(sucess)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given the requirements are met, the probability distribution of our binary event has a mean of &lt;span class=&#34;math inline&#34;&gt;\(np\)&lt;/span&gt; and variance of &lt;span class=&#34;math inline&#34;&gt;\(np(1-p)\)&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Example&lt;/h3&gt;
&lt;p&gt;Kehjistanian scientists have identified the gene NPHLM on the locus 14p.61 which predisposes children to a certain lifestyle.&lt;/p&gt;
&lt;p&gt;It is estimated that 1 in 40 child under the age of 16 have this mutation. According to the last census at &lt;a href=&#34;http://diablo.wikia.com/wiki/Caldeum&#34;&gt;Caldeum&lt;/a&gt;, number of kids under 16 is roughly 400,000.&lt;/p&gt;
&lt;p&gt;A sample of 200 has been collected. How many children with NPHLM mutation can we expect to find?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N = 400000
n = 200
p = 1/40
x = rep(0,N)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for (i in 1:N){{
  x[i] = sum(runif(n)&amp;lt;p)
}}
hist(x, main = &amp;quot;Distribution of NPHLM mutation in a sample of 200&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/statistics/probability/pmf_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
      
    </item>
    
    <item>
      <title>Regression Introduction: Example</title>
      <link>/post/regression/1-introduction/regression-introduction-example/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/regression/1-introduction/regression-introduction-example/</guid>
      
        <description>&lt;p&gt;Example 2 - why ? ??&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Regression Introduction: Example</title>
      <link>/post/regression/1-introduction/regression-introduction-example/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/regression/1-introduction/regression-introduction-example/</guid>
      
        <description>&lt;p&gt;regression example 1;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Regression: Introduction</title>
      <link>/post/regression/1-introduction/regression-1-introduction/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/regression/1-introduction/regression-1-introduction/</guid>
      
        <description>&lt;p&gt;This is the page for regression.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;../regression-introduction-example/&#34;&gt;link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;../regression-introduction-example-2/&#34;&gt;example 2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://127.0.0.1:4321/regression/1-introduction/example-1/&#34; class=&#34;uri&#34;&gt;http://127.0.0.1:4321/regression/1-introduction/example-1/&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
---
title: Inference
author: Alireza Behzadnia
date: '2018-03-08'
slug: bayesian-inference
categories:
  - Bayesian
tags:
  - Bayesian
weight: 2
---



<p>In order to have a better understanding of the difference between the frequentist approach and the Bayesian approach to interference let’s use the following example:</p>
<div id="efficacy-of-ru-486-as-an-emergency-pill" class="section level2">
<h2>Efficacy of RU-486 as an emergency pill</h2>
<p>A randomized control trial was carried out to ask the question of whether Mifepristone (RU486) can be an effective morning after contraceptive. The study participants were 40 women who came to a health clinic asking for emergency contraception. <strong>Method:</strong> 20 women were randomly assigned to receive RU-486, and another 20 to receive standard therapy, consisting of high doses of estrogen and synthetic progesterone. <strong>Results:</strong> In the treatment group (RU-486), 4 became pregnant. In the control group, 16 became pregnant.</p>
<p>How can we infere from our data? Let’s look at both aproaches:</p>
<hr />
<div id="frequentist-approach" class="section level3">
<h3>Frequentist approach</h3>
<p>In the frequentist approach, we first need to set our hypotheses:</p>
<ul>
<li><em>P</em> = <em>P</em>(pregnancy comes from the treatment group)</li>
<li>Null hypothesis (H<sub>0</sub>) = P is equal to 0.5.
<ul>
<li><em>~P</em> = 1 - <em>P</em> = 0.5.</li>
<li>The pregnancy is equally likely to come from either the treatment or the control group.</li>
</ul></li>
<li>Alternative hypothesis (H<sub>a</sub>) = P &lt; 0.5
<ul>
<li><em>~P</em> &gt; <em>P</em></li>
<li>The pregnancy is more likely to come from the control group and less likely from the treatment group.</li>
</ul></li>
</ul>
<p>Within the frequentist paradigm, we need a p-value. <strong>P-value</strong> can be defined as the probability of an observed outcome given that the null hypothesis is true. Here we have 20 trials (<span class="math inline">\(n = 20\)</span>) where the outcome of each trial is <strong>independent</strong> of the others and we have based on our H<sub>0</sub>, each trial has a probability of <span class="math inline">\(p = 0.5\)</span>. The outcome of each trial can be either: 1. success (pregnancy prevented) or 2. failure (pregnancy occured).</p>
<p>Based on the study set up we can use binomial distribution to calculate the probability of observing 4 pregnancies (<span class="math inline">\(k = 4\)</span>), in 20 trials (<span class="math inline">\(n= 20\)</span>, given the probability of pregnancy occuring in each trial is <span class="math inline">\(p = 0.5\)</span> - assuming H<sub>0</sub> is true.</p>
<ul>
<li><span class="math inline">\(p - value = P(k \leq 4)\)</span></li>
</ul>
<pre class="r"><code>sum(dbinom(0:4, size = 20, p = 0.5))</code></pre>
<pre><code>## [1] 0.005908966</code></pre>
<p>This means,that the chances of observing 4 or fewer pregnancies in the treatment group is approximately 0.0059 - which is a small probability. Therefore, we can reject the null hypothesis and conclude that the data provides convincing evidence for the treatment being effective.</p>
</div>
<div id="bayesian-approach" class="section level3">
<h3>Bayesian approach</h3>
<p>Within the Bayesian framework too we first need to define our hypotheses. In Bayesian framework hypotheses can be seen as <strong>models</strong> that the data come from</p>
<p>We begin by delineating each of the plasible models. It is plausible for <em>P</em>(pregnancy comes from the treatment group) to take any value from 0 to 1. However, we’ll simplify the number of models we need to consider in this study by only considering a continuous parameter space for p that ranges from 10% to 90%. This means, we will look at 9 different models where each model the probability of pregnancy occuring given that they receieved treatment. For example, <em>model 1</em> (10%) states that if one of the participants becomes pregnant, the probability of them having received RU-486 is only 10%. Therefore,the likelihood of them being in the control group is 90%.</p>
<div id="prior" class="section level4">
<h4>Prior</h4>
<p>Next, we need to specify the prior probabilities assigned to these models (or hypotheses). The prior probabilities encapsulates what we know about possibility of the models (from previous research perhaps) before conducting the experiment. We will discuss further on how these prior probabilities are assigned. For now, we place <span class="math inline">\(P(model = 0.5) = 0.52\)</span> and the rest will be devided accross other models equally <span class="math inline">\(\frac{0.48}{8} =0.06\)</span>.</p>
<p>Therefore, if <strong>participant A</strong> becomes pregnant, it’s 50% likely that she received treatment (<span class="math inline">\(\small P(model=0.5)=0.52\)</span>, i.e. highest probability). This is based on the prior probability of the model 0.5:</p>
<p><span class="math display">\[\large Prior= P(model)\]</span></p>
<pre class="r"><code>models = seq(from = 0.10, to = 0.90, by = 0.10)
prior = c(rep(0.06, 4), 0.52, rep(0.06, 4))
names(prior) = models
barplot(prior, main = &quot;Prior probabilities&quot;)</code></pre>
<p><img src="/post/statistics/bayesian/2-inference/1index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="likelihood" class="section level4">
<h4>Likelihood</h4>
<p>Now we’re ready to calculate the probability of observed data, given each of the models that we’re considering. This probability is called the <strong>likelihood</strong>.</p>
<p>In this example, this is the <em>probability of the data, given the model</em> <span class="math inline">\(\small P(data|model)\)</span>. Probability of data in our example is <span class="math inline">\(k \leq 4\)</span> given that <span class="math inline">\(n = 20\)</span>. Here however, <em>p</em> has various values from 10-90%. We can again use the binomial distribution to calculate the probability of each model when <span class="math inline">\(k = 4\)</span>:</p>
<pre class="r"><code>likelihood = dbinom(4, size = 20, prob = models)
names(likelihood) = models
likelihood</code></pre>
<pre><code>##          0.1          0.2          0.3          0.4          0.5 
## 8.977883e-02 2.181994e-01 1.304210e-01 3.499079e-02 4.620552e-03 
##          0.6          0.7          0.8          0.9 
## 2.696862e-04 5.007558e-06 1.300570e-08 3.178804e-13</code></pre>
<pre class="r"><code>barplot(likelihood, main = &quot;Likelihood&quot;)</code></pre>
<p><img src="/post/statistics/bayesian/2-inference/1index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The number of successes and the number of trials are the same for each of these models, however each model has a different likelihood based on model’s probability of success. Likelihood is the probability of data given the model:</p>
<p><span class="math display">\[\large Lieklihood = P(data |model)\]</span></p>
</div>
<div id="posterior" class="section level4">
<h4>Posterior</h4>
<p>Now based on our <em>data</em> we can update our <em>prior probabilities</em> to calculate the <a href="https://en.wikipedia.org/wiki/Posterior_probability"><em>posterior probability</em></a>. In other words, probability of the model beign correct given the <a href="data:$$\large" class="uri">data:$$\large</a> Posterior = P(model|data) =  = $$</p>
<p>Here, we have calculated the Prior and the likelihood; we can also calculate <strong>evidence</strong>:</p>
<p><span class="math display">\[ Evidence = P(data) = P(data|model) \times P(model)\]</span> Since we have 9 models, <span class="math inline">\(P(data)\)</span> is <em>sum</em> of the evidence of <strong>every model</strong>.</p>
<pre class="r"><code>evidence = likelihood * prior
evidence = sum(evidence) # P(data) for all the plausible models
evidence  </code></pre>
<pre><code>## [1] 0.03082257</code></pre>
<p>Therefore, the posterior probability of each model is:</p>
<pre class="r"><code>posterior = (prior * likelihood)/evidence
posterior</code></pre>
<pre><code>##          0.1          0.2          0.3          0.4          0.5 
## 1.747658e-01 4.247525e-01 2.538808e-01 6.811397e-02 7.795220e-02 
##          0.6          0.7          0.8          0.9 
## 5.249779e-04 9.747841e-06 2.531722e-08 6.187942e-13</code></pre>
<pre class="r"><code>barplot(posterior, main = &quot;Posterior&quot;)</code></pre>
<p><img src="/post/statistics/bayesian/2-inference/1index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="model-selection" class="section level4">
<h4>Model selection</h4>
<p>Looking at the posterior probabilities above, the most likely model is <em>model 0.2</em> where <span class="math inline">\(P(model 0.2) = 0.425\)</span>.</p>
<p>Even though we had assigned a low prior to this model, the incorporation of the data gave this model a high probability. This should be surprising since 4 successes in 20 trials is 20%.</p>
<p>Based on this posterior, we can now update our beliefs and evidence - the current posterior becomes the next experiments Prior.</p>
<p>The Bayesian paradigm, unlike the frequentist approach, also allows us to make direct probability statements about our models. For example, we can calculate the probability that RU-486, is more effective than the control as the <strong>sum of the posteriors</strong> of the models where p is less than 0.5 (<em>based on the p</em>(H<sub>0</sub>) = 0.5).</p>
<pre class="r"><code>sum(posterior[1:4])</code></pre>
<pre><code>## [1] 0.921513</code></pre>
<p>So there is a 92.15% chance that the treatment is more effective than the control.</p>
</div>
</div>
</div>
